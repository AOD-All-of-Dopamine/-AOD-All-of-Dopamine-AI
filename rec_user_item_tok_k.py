# -*- coding: utf-8 -*-

#ìœ ì €/ì•„ì´í…œ ì„ë² ë”©ë§Œìœ¼ë¡œ Top-K ì¶”ì²œ (contents.csvì—ì„œ ì´ë¦„/ë„ë©”ì¸ê¹Œì§€ ë¶™ì´ê¸°)
#ì…ë ¥:
#  clean/user_embeddings.csv                  (user_id, username, emb_0..)
#  clean/item_embeddings_torch.csv ë˜ëŠ” item_embeddings.csv (content_id, emb_0..)
#  clean/contents.csv                         (content_id, master_title, domain)
#  clean/user_preferences.csv                 (ì„ íƒ) id, username  â† ì¶”ê°€ë¡œ ì‚¬ìš©
#ì¶œë ¥:
#  clean/recommendations_topK.csv             (user_id, username, rank, content_id, master_title, domain, score)

import os
import re
import numpy as np
import pandas as pd
from typing import Optional

BASE = r"csv ë°ì´í„°\clean"
USER_EMB   = os.path.join(BASE, "user_embeddings.csv")
ITEM_EMB_1 = os.path.join(BASE, "item_embeddings_torch.csv")
ITEM_EMB_2 = os.path.join(BASE, "item_embeddings.csv")
CONTENTS   = os.path.join(BASE, "contents.csv")
UPREF      = os.path.join(BASE, "user_preferences.csv")   # â˜… ì¶”ê°€
OUT_RECS   = os.path.join(BASE, "recommendations_topK.csv")

TOPK = 5
EXCLUDE_DUP_CONTENTS = True   # content_id ì¤‘ë³µí–‰ì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©
ASSUME_NORMALIZED = True      # ì„ë² ë”©ì´ ì´ë¯¸ L2 ì •ê·œí™”ë˜ì–´ ìˆë‹¤ë©´ True, ì•„ë‹ˆë©´ Falseë¡œ

def read_csv_retry(path, encodings=("utf-8-sig","utf-8","cp949","euc-kr","latin1"), **kw) -> Optional[pd.DataFrame]:
    if not os.path.exists(path):
        return None
    last=None
    for enc in encodings:
        try:
            return pd.read_csv(path, encoding=enc, **kw)
        except Exception as e:
            last=e
    raise last

def l2norm(X: np.ndarray) -> np.ndarray:
    return X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-12)

def _coerce_content_id_column(df: pd.DataFrame) -> pd.Series:
    """ì—¬ëŸ¬ ì´ë¦„/í˜•íƒœë¡œ ì €ì¥ëœ content_idë¥¼ ìµœëŒ€í•œ ë³µêµ¬."""
    df = df.copy()
    orig_cols = list(df.columns)
    df.columns = [c.strip() for c in df.columns]
    name_map = {c.lower(): c for c in df.columns}
    for key in ["content_id", "contentid", "content id", "id", "unnamed: 0"]:
        if key in name_map:
            cand = name_map[key]
            s = df[cand]
            if s.dtype == object:
                s = s.astype(str).str.strip()
            s = pd.to_numeric(s, errors="coerce").astype("Int64")
            if s.isna().all():
                continue
            return s
    raise RuntimeError(f"content_id ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ì»¬ëŸ¼: {orig_cols}")

def load_user_embeddings() -> pd.DataFrame:
    u = read_csv_retry(USER_EMB)
    if u is None or u.empty:
        raise RuntimeError("user_embeddings.csv í•„ìš”.")
    u = u.copy()
    u.columns = [c.strip() for c in u.columns]

    # user_id ì •ë¦¬
    if "user_id" not in u.columns:
        if "id" in u.columns:
            u = u.rename(columns={"id": "user_id"})
        else:
            raise RuntimeError("user_embeddings.csvì— user_id ì»¬ëŸ¼ í•„ìš”.")
    u["user_id"] = pd.to_numeric(u["user_id"], errors="coerce").astype("Int64")
    u = u[u["user_id"].notna()].copy()
    u["user_id"] = u["user_id"].astype(int)

    # ì„ë² ë”© ì»¬ëŸ¼
    emb_cols = [c for c in u.columns if c.lower().startswith("emb_")]
    if not emb_cols:
        raise RuntimeError("user_embeddings.csvì— emb_ë¡œ ì‹œì‘í•˜ëŠ” ì„ë² ë”© ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    for c in emb_cols:
        u[c] = pd.to_numeric(u[c], errors="coerce")
    u.dropna(subset=emb_cols, inplace=True)
    if not ASSUME_NORMALIZED:
        u.loc[:, emb_cols] = l2norm(u[emb_cols].to_numpy(np.float32))

    # username ì»¬ëŸ¼ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    lower_cols = [x.lower() for x in u.columns]
    if "username" in lower_cols:
        uname_col = u.columns[lower_cols.index("username")]
        cols = ["user_id", uname_col] + emb_cols
        out = u[cols].copy()
        if uname_col != "username":
            out = out.rename(columns={uname_col: "username"})
    else:
        cols = ["user_id"] + emb_cols
        out = u[cols].copy()
        out["username"] = ""

    # ğŸ”¹ 1ë‹¨ê³„: user_preferences.csvì—ì„œ username ë³´ê°•
    pref = read_csv_retry(UPREF)
    if pref is not None and not pref.empty:
        pref = pref.copy()
        pref.columns = [c.strip() for c in pref.columns]
        lower = {c.lower(): c for c in pref.columns}

        id_col    = lower.get("id") or lower.get("user_id")
        uname_col = lower.get("username") or lower.get("user_name")

        if id_col is not None and uname_col is not None:
            pref = pref[[id_col, uname_col]].dropna(subset=[id_col])
            pref[id_col] = pd.to_numeric(pref[id_col], errors="coerce").astype("Int64")
            pref = pref[pref[id_col].notna()].copy()
            pref[id_col] = pref[id_col].astype(int)
            pref = pref.rename(columns={id_col: "user_id", uname_col: "username_pref"})

            out = out.merge(pref, on="user_id", how="left")
            # user_embeddingsì˜ usernameì´ ë¹„ì–´ìˆìœ¼ë©´ preferencesì˜ username_prefë¡œ ì±„ìš°ê¸°
            out["username"] = out["username"].astype(str)
            out["username_pref"] = out["username_pref"].astype(str)

            # embeddings ìª½ usernameì´ ì—†ê±°ë‚˜ "nan"/"None" ê°™ì€ ê°’ì´ë©´ pref ê²ƒìœ¼ë¡œ ë®ì–´ì“°ê¸°
            mask_missing = out["username"].str.strip().eq("") | \
                           out["username"].str.strip().str.lower().isin(["nan", "none"])
            out.loc[mask_missing, "username"] = out.loc[mask_missing, "username_pref"]
            out = out.drop(columns=["username_pref"])

    # ğŸ”¹ 2ë‹¨ê³„: ìµœì¢…ì ìœ¼ë¡œ ë‚¨ì€ ì´ìƒê°’ ì •ë¦¬
    out["username"] = out["username"].replace({np.nan: ""})
    out["username"] = out["username"].astype(str)
    bad = out["username"].str.strip().str.lower().isin(["nan", "none"])
    out.loc[bad, "username"] = ""

    return out[["user_id", "username"] + emb_cols]

def load_item_embeddings() -> pd.DataFrame:
    i1 = read_csv_retry(ITEM_EMB_1)
    if i1 is not None and not i1.empty:
        df = i1; src = os.path.basename(ITEM_EMB_1)
    else:
        i2 = read_csv_retry(ITEM_EMB_2)
        if i2 is None or i2.empty:
            raise RuntimeError("item_embeddings CSV í•„ìš”: item_embeddings_torch.csv ë˜ëŠ” item_embeddings.csv")
        df = i2; src = os.path.basename(ITEM_EMB_2)

    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    df["content_id"] = _coerce_content_id_column(df)

    emb_cols = [c for c in df.columns if c.lower().startswith("emb_")]
    if not emb_cols:
        alt = [c for c in df.columns if re.search(r"\d+$", c)]
        raise RuntimeError(f"ì„ë² ë”© ì»¬ëŸ¼(emb_*) ì—†ìŒ. í™•ì¸ í•„ìš”. í›„ë³´: {alt}")

    for c in emb_cols:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    df = df.dropna(subset=emb_cols + ["content_id"]).copy()
    df["content_id"] = df["content_id"].astype(int)

    if EXCLUDE_DUP_CONTENTS:
        df = df.drop_duplicates(subset=["content_id"], keep="first").reset_index(drop=True)

    if not ASSUME_NORMALIZED:
        df.loc[:, emb_cols] = l2norm(df[emb_cols].to_numpy(np.float32))

    print(f"âœ… ì•„ì´í…œ ì„ë² ë”© ë¡œë“œ: {src} (items={len(df)}, dim={len(emb_cols)})")
    return df[["content_id"] + emb_cols]

def load_contents_meta() -> Optional[pd.DataFrame]:
    """
    contents.csvì—ì„œ content_id, master_title, domainë§Œ ë½‘ì•„ì„œ ë¦¬í„´.
    content_idëŠ” ìœ„ì˜ _coerce_content_id_column ë¡œ í†µì¼.
    """
    c = read_csv_retry(CONTENTS)
    if c is None or c.empty:
        print("âš ï¸ contents.csvë¥¼ ì°¾ì§€ ëª»í•´ ì´ë¦„/ë„ë©”ì¸ ë§¤í•‘ ì—†ì´ ì €ì¥í•©ë‹ˆë‹¤.")
        return None

    c = c.copy()
    c.columns = [col.strip() for col in c.columns]

    # content_id ê°•ì œ ì¶”ì¶œ
    c["content_id"] = _coerce_content_id_column(c)
    c = c[c["content_id"].notna()].copy()
    c["content_id"] = c["content_id"].astype(int)

    # master_title / domain ì»¬ëŸ¼ ì´ë¦„(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ) ì°¾ê¸°
    lower_map = {col.lower(): col for col in c.columns}
    title_col = lower_map.get("master_title")
    domain_col = lower_map.get("domain")

    if title_col is None:
        raise RuntimeError("contents.csvì—ì„œ master_title ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    if domain_col is None:
        raise RuntimeError("contents.csvì—ì„œ domain ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    meta = c[["content_id", title_col, domain_col]].copy()
    # ì»¬ëŸ¼ ì´ë¦„ í†µì¼
    if title_col != "master_title":
        meta = meta.rename(columns={title_col: "master_title"})
    if domain_col != "domain":
        meta = meta.rename(columns={domain_col: "domain"})

    meta = meta.drop_duplicates(subset=["content_id"], keep="first").reset_index(drop=True)
    print(f"âœ… contents ë©”íƒ€ ë¡œë“œ: {len(meta)} rows (content_id, master_title, domain)")
    return meta

def main():
    u = load_user_embeddings()
    i = load_item_embeddings()
    meta = load_contents_meta()  # ì´ë¦„/ë„ë©”ì¸ ë§¤í•‘

    ucols = [c for c in u.columns if c.lower().startswith("emb_")]
    icols = [c for c in i.columns if c.lower().startswith("emb_")]

    U = u[ucols].to_numpy(np.float32)
    I = i[icols].to_numpy(np.float32)

    # í˜¹ì‹œ ASSUME_NORMALIZED=Trueì¸ë° ì‹¤ì œë¡œ ì •ê·œí™” ì•ˆë˜ì–´ ìˆìœ¼ë©´, ì½”ì‚¬ì¸ = ë‚´ì ì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë‹ˆ ë³´ì •
    U = l2norm(U)
    I = l2norm(I)

    item_ids = i["content_id"].to_numpy(int)
    user_ids = u["user_id"].to_numpy(int)
    usernames = u["username"].astype(str).to_numpy() if "username" in u.columns else np.array([""]*len(u))

    rec_rows = []
    for r in range(U.shape[0]):
        sims = (I @ U[r:r+1].T).reshape(-1)   # ì½”ì‚¬ì¸(ì •ê·œí™” ê°€ì •)
        k = min(TOPK, len(sims))
        if k == 0:
            continue
        part = np.argpartition(-sims, k-1)[:k]
        order = part[np.argsort(-sims[part])]
        top_ids = item_ids[order]
        top_scs = sims[order]
        uid = int(user_ids[r]); uname = usernames[r] if r < len(usernames) else ""
        for rank, (cid, sc) in enumerate(zip(top_ids, top_scs), start=1):
            rec_rows.append([uid, uname, rank, int(cid), float(sc)])

    rec = pd.DataFrame(rec_rows, columns=["user_id","username","rank","content_id","score"])

    # contents ë©”íƒ€ì™€ merge í•´ì„œ master_title, domain ì¶”ê°€
    if meta is not None:
        rec = rec.merge(meta, on="content_id", how="left")
        cols = ["user_id", "username", "rank", "content_id", "master_title", "domain", "score"]
        cols = [c for c in cols if c in rec.columns]
        rec = rec[cols]

    rec.sort_values(["user_id","rank"]).to_csv(OUT_RECS, index=False, encoding="utf-8-sig")
    print(f"âœ… recommendations_topK.csv ì €ì¥: {OUT_RECS} (rows={len(rec)})")

if __name__ == "__main__":
    main()
